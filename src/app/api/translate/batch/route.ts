import { NextRequest, NextResponse } from "next/server";
import OpenAI from "openai";

// Initialize OpenAI client
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

export async function POST(request: NextRequest) {
  try {
    const { texts } = await request.json();

    if (!texts || !Array.isArray(texts)) {
      return NextResponse.json(
        { success: false, error: "texts array is required" },
        { status: 400 }
      );
    }

    if (texts.length === 0) {
      return NextResponse.json({
        success: true,
        translations: [],
      });
    }

    console.log("üîÑ Starting batch translation for", texts.length, "texts");

    // Process translations in batches to avoid rate limits
    const batchSize = 5;
    const translations: string[] = [];

    for (let i = 0; i < texts.length; i += batchSize) {
      const batch = texts.slice(i, i + batchSize);
      console.log(
        `üìù Translating batch ${Math.floor(i / batchSize) + 1}/${Math.ceil(
          texts.length / batchSize
        )}`
      );

      try {
        // Create a single prompt with multiple texts for efficiency
        const prompt = `Îã§Ïùå ÏòÅÏñ¥ Î¨∏Ïû•Îì§ÏùÑ ÏûêÏó∞Ïä§Îü¨Ïö¥ ÌïúÍµ≠Ïñ¥Î°ú Î≤àÏó≠Ìï¥Ï£ºÏÑ∏Ïöî. Í∞Å Î≤àÏó≠ÏùÄ ÏÉà Ï§ÑÎ°ú Íµ¨Î∂ÑÌï¥ÏÑú ÎãµÎ≥ÄÌï¥Ï£ºÏÑ∏Ïöî:

${batch.map((text, idx) => `${idx + 1}. ${text}`).join("\n")}`;

        const completion = await openai.chat.completions.create({
          model: "gpt-4o-mini",
          messages: [
            {
              role: "system",
              content:
                "You are a professional translator. Translate English text to natural Korean. Respond with only the Korean translations, each on a new line, maintaining the same order as the input.",
            },
            {
              role: "user",
              content: prompt,
            },
          ],
          temperature: 0.3,
          max_tokens: 2000,
        });

        const response = completion.choices[0].message.content;
        if (response) {
          // Split the response by lines and clean up
          const batchTranslations = response
            .split("\n")
            .map((line) => line.replace(/^\d+\.\s*/, "").trim()) // Remove numbering
            .filter((line) => line.length > 0);

          // Ensure we have the same number of translations as inputs
          for (let j = 0; j < batch.length; j++) {
            translations.push(batchTranslations[j] || "Î≤àÏó≠ Ïã§Ìå®");
          }
        } else {
          // Fill with error messages if no response
          for (let j = 0; j < batch.length; j++) {
            translations.push("Î≤àÏó≠ Ïã§Ìå®");
          }
        }

        // Small delay between batches to respect rate limits
        if (i + batchSize < texts.length) {
          await new Promise((resolve) => setTimeout(resolve, 100));
        }
      } catch (batchError) {
        console.error(
          `‚ùå Batch translation failed for batch ${
            Math.floor(i / batchSize) + 1
          }:`,
          batchError
        );

        // Fill failed batch with error messages
        for (let j = 0; j < batch.length; j++) {
          translations.push("Î≤àÏó≠ Ïã§Ìå®");
        }
      }
    }

    console.log(
      "‚úÖ Batch translation completed:",
      translations.length,
      "translations"
    );

    return NextResponse.json({
      success: true,
      translations,
    });
  } catch (error) {
    console.error("üí• Translation API error:", error);
    return NextResponse.json(
      {
        success: false,
        error: error instanceof Error ? error.message : "Translation failed",
      },
      { status: 500 }
    );
  }
}
